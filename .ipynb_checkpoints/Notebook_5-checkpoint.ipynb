{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trees, Forests, and Democracy</h1>\n",
    "<p>\n",
    "    A new class of models will be featured in this notebook. But before we dive into it, lets sum up what we saw until now :\n",
    "    <ul>\n",
    "        <li>A Data Science project <em>always</em> starts with an <em>exploratory</em> phase</li>\n",
    "        <li>Given a target, we can produce simple models that will establish correlations between what we aim to predict and <em>features</em> </li>\n",
    "        <li>Any <em>categorical</em> feature can be (and must be) turned into numerical values.</li>\n",
    "        <li> Also, new features can be created by combining other ones</li>\n",
    "        <li>A model can be used to perform classification or regression depending on whether the target is categorical (or binary as we saw it) or continuous (as it was the case in the third notebook)</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<h2>Classification Trees </h2>\n",
    "<p>\n",
    "    The following cells will introduce you a new type of models : the classification trees. They work by learning simple rules on the features that will cut the dataset into smaller subsets</p>\n",
    "    <img src=\"https://www.ibm.com/support/knowledgecenter/SS3RA7_15.0.0/com.ibm.spss.modeler.help/images/dectree.gif\" />\n",
    "<p>\n",
    "    The <em>parameters</em> of a such model are the rules of each node, and the topography of the tree. To classify a sample, the model will simply make it flow through each node until it reaches a leaf.\n",
    "</p>\n",
    "<p>\n",
    "    The learning process works by fiding <em>optimal</em> cuts. A cut is a split over a feature depending on a certain value : <code>price_first_item_purchased</code> > 125\\$ for exemple is a cut.\n",
    "    <br >\n",
    "    To find those cuts, the algorithm uses a mesure called the <em>Gini impurty</em> : it represents the probability of miss-classifying a sample based on a certain cut. The <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning\">CART</a> algorithm aims the lowest impurty when building nodes. It looks for <em>purety</em> when performing splits. The training process ends when the classification score is above a minimal threshold, or when the tree contains a certain amount of node, or reaches a maximal height.\n",
    "</p>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*gx6XsQ8X_KEs7R05.png\" />\n",
    "<p>\n",
    "    The main benefit of the classification trees is their explainability : each and every sample is classified based on simple and <em>human-readable</em> rules : no eplicit probabilities or coefficients are involved (as opposed to Logistic and Linear Regressions).\n",
    "</p>\n",
    "<p>\n",
    "Lets build all the features we need and assemble them : numerical, categorical, and computed features.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the usuals packages and the model from sklearn \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./customerLifetimeValue.csv\", sep=\";\")\n",
    "#We take the columns we need for our models and get the underlying matrix\n",
    "X_numeric = dataset[[\"price_first_item_purchased\",  \"since_birth_parsed_days\"]].values.copy()\n",
    "#We also take a categorical variable\n",
    "X_categorical = dataset[[\"Country\", \"gender\"]].copy()\n",
    "#and we create a new feature\n",
    "dataset[\"priceByVisited_pages\"] = dataset[\"price_first_item_purchased\"] / dataset[\"pages_visited\"]\n",
    "X_new_feature  = dataset[\"priceByVisited_pages\"].values.reshape((-1, 1))\n",
    "#We binarize the target, all value greater than a given revenue will become positive (1), other negative(0)\n",
    "Y = dataset[\"revenue\"].values\n",
    "Y[Y <= 175] = 0\n",
    "Y[Y > 175] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The cell above loads the features. The cell below replaces missing values by \"unknown\" and produces a column for each possible categorical value (remember the notebook nÂ°4).\n",
    "</p> \n",
    "<p>\n",
    "    In the following cell, you can notice that one <code>LabelBinarizer</code> is needed per feature.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical.fillna(\"unknown\", inplace=True)\n",
    "CountryBinarizer = LabelBinarizer()\n",
    "genderBinarizer = LabelBinarizer()\n",
    "binCountries = CountryBinarizer.fit_transform(X_categorical[\"Country\"])\n",
    "binGenders = genderBinarizer.fit_transform(X_categorical[\"gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    At this stage, the X variable contains all the features and the Y all the targets values (revenue >175\\$). We will use a tree classifier as a model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All features are concatenated to produce the final X variable\n",
    "X = np.hstack([X_numeric, binCountries, binGenders, 1-binGenders, X_new_feature])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Above : splitting the dataset in test and train sets <br /> Below : training a model (note how the api is the same for every model).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=8, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_leaf_nodes=8)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Similarly, testing the model is as simple as :\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7379253283690144\n"
     ]
    }
   ],
   "source": [
    "Yhat = model.predict(X_test)\n",
    "print(accuracy_score(Y_test, Yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    It's a very decent score considering the size of the dataset and the nature of the model. Now, lets see how we can interpret those results and better understand the model we've produce : the previous models we saw used coefficients associated to each feature. The model automatically established correlations and learned the propper parameters. Trees work differently.\n",
    "</p>\n",
    "<p>\n",
    "    A tree classifier will try to find the most relevant splits (or cuts). It looks for discriminative values in our features with regard to the target. The node of the tree can be displayed using <a href=\"http://webgraphviz.com/\">this link</a> : copy-paste the result of the execution of the following cell :\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\r\n",
      "node [shape=box] ;\r\n",
      "0 [label=\"price_first_item_purchased <= 35.0\\ngini = 0.499\\nsamples = 19630\\nvalue = [10231, 9399]\\nclass = Low Revenue\"] ;\r\n",
      "1 [label=\"united states <= 0.5\\ngini = 0.413\\nsamples = 9263\\nvalue = [6565, 2698]\\nclass = Low Revenue\"] ;\r\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\r\n",
      "5 [label=\"gini = 0.275\\nsamples = 5601\\nvalue = [4680, 921]\\nclass = Low Revenue\"] ;\r\n",
      "1 -> 5 ;\r\n",
      "6 [label=\"since_birth_parsed_days <= 102.0\\ngini = 0.5\\nsamples = 3662\\nvalue = [1885, 1777]\\nclass = Low Revenue\"] ;\r\n",
      "1 -> 6 ;\r\n",
      "9 [label=\"gini = 0.493\\nsamples = 3187\\nvalue = [1410, 1777]\\nclass = High Revenue\"] ;\r\n",
      "6 -> 9 ;\r\n",
      "10 [label=\"gini = 0.0\\nsamples = 475\\nvalue = [475, 0]\\nclass = Low Revenue\"] ;\r\n",
      "6 -> 10 ;\r\n",
      "2 [label=\"united states <= 0.5\\ngini = 0.457\\nsamples = 10367\\nvalue = [3666, 6701]\\nclass = High Revenue\"] ;\r\n",
      "0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\r\n",
      "3 [label=\"price_first_item_purchased <= 67.5\\ngini = 0.5\\nsamples = 6258\\nvalue = [3168, 3090]\\nclass = Low Revenue\"] ;\r\n",
      "2 -> 3 ;\r\n",
      "7 [label=\"china <= 0.5\\ngini = 0.481\\nsamples = 4706\\nvalue = [2810, 1896]\\nclass = Low Revenue\"] ;\r\n",
      "3 -> 7 ;\r\n",
      "11 [label=\"since_birth_parsed_days <= 106.0\\ngini = 0.497\\nsamples = 3923\\nvalue = [2114, 1809]\\nclass = Low Revenue\"] ;\r\n",
      "7 -> 11 ;\r\n",
      "13 [label=\"gini = 0.5\\nsamples = 3421\\nvalue = [1692, 1729]\\nclass = High Revenue\"] ;\r\n",
      "11 -> 13 ;\r\n",
      "14 [label=\"gini = 0.268\\nsamples = 502\\nvalue = [422, 80]\\nclass = Low Revenue\"] ;\r\n",
      "11 -> 14 ;\r\n",
      "12 [label=\"gini = 0.198\\nsamples = 783\\nvalue = [696, 87]\\nclass = Low Revenue\"] ;\r\n",
      "7 -> 12 ;\r\n",
      "8 [label=\"gini = 0.355\\nsamples = 1552\\nvalue = [358, 1194]\\nclass = High Revenue\"] ;\r\n",
      "3 -> 8 ;\r\n",
      "4 [label=\"gini = 0.213\\nsamples = 4109\\nvalue = [498, 3611]\\nclass = High Revenue\"] ;\r\n",
      "2 -> 4 ;\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "featuresNames = [\"price_first_item_purchased\",  \"since_birth_parsed_days\"] + list(CountryBinarizer.classes_) + list(genderBinarizer.classes_) + [\"priceByVisited_pages\"]\n",
    "dot_data = tree.export_graphviz(treeClassifier ,out_file=\"./graph.dot\", class_names=[\"Low Revenue\", \"High Revenue\"], feature_names=featuresNames)\n",
    "! cat graph.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['albania', 'algeria', 'angola', 'argentina', 'armenia',\n",
       "       'australia', 'austria', 'azerbaijan', 'bahrain', 'bangladesh',\n",
       "       'belarus', 'belgium', 'belize', 'benin', 'bolivia',\n",
       "       'bosnia and herzegovina', 'botswana', 'brazil', 'brunei',\n",
       "       'bulgaria', 'cambodia', 'cameroon', 'canada', 'chile', 'china',\n",
       "       'colombia', 'costa rica', 'croatia', 'cyprus', 'denmark',\n",
       "       'djibouti', 'dominican republic', 'ecuador', 'egypt',\n",
       "       'el salvador', 'estonia', 'ethiopia', 'fiji', 'finland', 'france',\n",
       "       'gabon', 'georgia', 'germany', 'ghana', 'greece', 'guatemala',\n",
       "       'guyana', 'haiti', 'honduras', 'hong kong', 'hungary', 'iceland',\n",
       "       'india', 'indonesia', 'iran', 'ireland', 'israel', 'italy',\n",
       "       'jamaica', 'japan', 'kazakhstan', 'kenya', 'kuwait', 'kyrgyzstan',\n",
       "       'latvia', 'lebanon', 'liberia', 'libya', 'luxembourg', 'malawi',\n",
       "       'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius',\n",
       "       'mexico', 'montenegro', 'morocco', 'mozambique', 'namibia',\n",
       "       'nepal', 'netherlands', 'new zealand', 'nicaragua', 'nigeria',\n",
       "       'norway', 'oman', 'pakistan', 'panama', 'papua new guinea',\n",
       "       'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar',\n",
       "       'romania', 'russia', 'rwanda', 'samoa', 'saudi arabia', 'senegal',\n",
       "       'serbia', 'seychelles', 'singapore', 'slovenia', 'south africa',\n",
       "       'spain', 'sri lanka', 'sudan', 'suriname', 'sweden', 'switzerland',\n",
       "       'taiwan', 'tanzania', 'thailand', 'togo', 'trinidad and tobago',\n",
       "       'tunisia', 'turkey', 'ukraine', 'united arab emirates',\n",
       "       'united kingdom', 'united states', 'unknown', 'uruguay',\n",
       "       'uzbekistan', 'venezuela', 'vietnam'], dtype='|S22')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountryBinarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
