{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps\n",
    "\n",
    "In this notebook we will discover few essentials ideas about model selection.\n",
    "We will test one of the most basic models : the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the usuals packages and the model from sklearn \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    29299.000000\n",
      "mean       177.451654\n",
      "std         69.052396\n",
      "min         28.000000\n",
      "25%        133.000000\n",
      "50%        172.000000\n",
      "75%        217.000000\n",
      "max        549.000000\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/Users/jeanbaptiste/Downloads/customerLifetimeValue.csv\", sep=\";\")\n",
    "#We take the columns we need for our models and get the underlying matrix\n",
    "X = dataset[[\"price_first_item_purchased\", \"pages_visited\"]].values\n",
    "#We binarize the target, all value greater than a given revenue will become positive (1), other negative(0)\n",
    "y = dataset[\"revenue\"].values\n",
    "print(dataset[\"revenue\"].describe())\n",
    "y[y <= 175] = 0\n",
    "y[y > 175] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate model's precision, we need to test is with data the model didn't fit on. We will split our sample in two dataframes : test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are simple, fast to fit and easily understandable. Those models have good performances on small and medium datasets. \n",
    "We will fit a very simple model on the train data. Note the model API is the same on the whole sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important thing about the precision of a model is to choose a metric. Here we will chose the R2 metric, but there are a lot of precision criterion for classification or regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.589723, test score : 0.582032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "train_score = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_score = roc_auc_score(y_test, model.predict(X_test))\n",
    "print(\"train score : %f, test score : %f\"%(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the score we get here can be biased. There is a probability to get a specific subsamble when splitting. To avoid it, we can use K-Fold validation.\n",
    "With K-fold validation, we train the model on all the folds except one, test precision on the last fold. Then we put back the test set with the other sets and take another fold as test fold. We repeat those steps until all folds have been used as test fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.693303, test score : 0.693174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "folds_maker = KFold(n_splits=10)\n",
    "train_score = []\n",
    "test_score = []\n",
    "for train_index, test_index in folds_maker.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score.append(roc_auc_score(y_train, model.predict(X_train)))\n",
    "    test_score.append(roc_auc_score(y_test, model.predict(X_test)))\n",
    "print(\"train score : %f, test score : %f\"%(np.mean(train_score), np.mean(test_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model one time per fold, so this method can become really slow if the model takes time to fit.\n",
    "Now it's your turn : fit another linear model with two variables of your choice and evaluate model performance with a train-test split and a K-Fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
